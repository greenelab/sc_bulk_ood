{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"stepwise_stacked_mnist.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1KHDOxnFtDwKpBs6lgSJe8OnQKcIY3xkb","authorship_tag":"ABX9TyPF+01+iDkGgvQwVwiq88sr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"eFbf9KYjEdTP"},"source":["# **Intro**\n","In this notebook I set up conditional semi-supervised VAE that attempts to predict the proportions of MNIST numbers that have been superimposed on top of one another.\n","\n","This is similar to the DIVA, where we use the rotation as labels and instead of having partially labeled numbers, we will have partially labeled number proportions. \n","In that setup some labels are ommited to make it semi-supervised, which we will also do.\n","This will mimic the idea that we have bulk case vs. control examples (we don't know the proportions) and  simulate bulk samples from single-cell profiles, (where we don't have treatment data).\n","Using both of these sources of data we hope that we can work in OOD stuff.\n","Also, we use the M1+M2 formulation of semi-supervised as described here: \"Semi-supervised Learning with Deep Generative Models\", https://arxiv.org/abs/1406.5298\n","\n","The difference in this model are the following: \n","\n","\n","1.   We are learning proportions of numbers in an image, not a specific number.\n","This means that this is regression, not classification.\n","2.   We put the constraint directly on mu, not on an external classifier.\n","This is because we want to be able to augment mu and reconstruct in a logical manner.\n","For example, we want to be able to simulate the mixture of specific cell types by augmenting mu.\n","3.   We add in an additional classification loss for classification of treated vs. untreated.\n","We hope that by learning two separate processes (stack proportions and case/control classification) we will have enough information to compose them and handle out-of-distribution responses.\n","This did not work when we simply used the treatment as a condition, instead we will need to have a downstream classifier, linked to z, that will predict treatment status.\n","\n","\n","\n","A lot of the model code was taken from this tutorial: https://github.com/nnormandin/Conditional_VAE/blob/master/Conditional_VAE.ipynb\n","\n","And this tutorial: https://github.com/bjlkeng/sandbox/tree/master/notebooks/vae-semi_supervised_learning with an awesome accomanying blogpost: https://bjlkeng.github.io/posts/semi-supervised-learning-with-variational-autoencoders/\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jlivQ5ASIUhV"},"source":["# **Github / VM setup**\n","\n","To integrate Colab with github, we need to do some setup first.\n","If you want this to integrate with your own github repo, you will need to create a `secrets` folder that contain your public and private key, and register this to access you github repo. Check `setup.sh` for more details."]},{"cell_type":"code","metadata":{"id":"kHC12IYgkk6w"},"source":["import os, sys\n","\n","NB_ROOT_PATH = '/content/drive/MyDrive/Colab Notebooks/checkouts/sc_bulk_ood'\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/checkouts/sc_bulk_ood')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jw2kPcPN2Fu0","executionInfo":{"status":"ok","timestamp":1628802564312,"user_tz":360,"elapsed":760,"user":{"displayName":"Natalie Davidson","photoUrl":"","userId":"15546154464477998770"}},"outputId":"12120969-9403-44ad-a145-1859aedef8ec"},"source":["# prelude: set up git, etc.\n","%cd {NB_ROOT_PATH}\n","!( source setup.sh )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/checkouts/sc_bulk_ood\n","Ensuring ssh keys exist...\n","Copied key(s) to /root/.ssh/\n","total 12\n","-rw-r--r-- 1 root root  43 Aug 12 21:09 config\n","-rw------- 1 root root 432 Aug 12 21:09 id_rsa\n","-rw-r--r-- 1 root root 113 Aug 12 21:09 id_rsa.pub\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BbcZkMSviyel"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5YoaF5Bo6oJ_","executionInfo":{"status":"ok","timestamp":1628802564984,"user_tz":360,"elapsed":536,"user":{"displayName":"Natalie Davidson","photoUrl":"","userId":"15546154464477998770"}},"outputId":"b5fd5494-4a34-405d-b4de-1ec020896271"},"source":["%%bash\n","# do your git operations here\n","git status"],"execution_count":null,"outputs":[{"output_type":"stream","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\tmodified:   experiments/DIVA_stacked_mnist.ipynb\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uRAJ0Mp8I-1r"},"source":["# **Imports**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wLkBHsDcDuvB","executionInfo":{"status":"ok","timestamp":1628802564985,"user_tz":360,"elapsed":9,"user":{"displayName":"Natalie Davidson","photoUrl":"","userId":"15546154464477998770"}},"outputId":"35c6cd3a-cf68-4cf4-8cf2-31ea3ddb12a6"},"source":["# general imports\n","import warnings\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense, Lambda, Flatten, Softmax, ReLU, ELU, LeakyReLU\n","from keras.layers.merge import concatenate as concat\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.losses import mean_absolute_error, mean_squared_error\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.activations import relu\n","from tensorflow.keras.utils import to_categorical, normalize\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam, SGD\n","import matplotlib.pyplot as plt\n","from scipy.spatial import distance_matrix\n","from scipy.spatial.distance import euclidean\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import accuracy_score\n","\n","\n","# Images, plots, display, and visualization\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","import cv2\n","from sklearn.manifold import TSNE\n","\n","# programming stuff\n","import time\n","import os\n","import pickle\n","from pathlib import Path\n","\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","# load methods from other files\n","from mnist_preprocessing import generate_data as gd\n","\n","# I disable eager execution ... forgot why\n","from tensorflow.python.framework.ops import disable_eager_execution\n","disable_eager_execution()\n","\n","warnings.filterwarnings('ignore')\n","%pylab inline"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n","Populating the interactive namespace from numpy and matplotlib\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0nCGlNkGED4T"},"source":["# **Load / Pre-process data**\n","Import + reshape the non-rotated MNIST data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6q3KfV9TV2U4","executionInfo":{"status":"ok","timestamp":1628802565760,"user_tz":360,"elapsed":781,"user":{"displayName":"Natalie Davidson","photoUrl":"","userId":"15546154464477998770"}},"outputId":"98bf5281-141a-4952-c17d-4f8c44ce6b1b"},"source":["(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n","\n","print(X_train.shape)\n","print(X_test.shape)\n","\n","X_train = X_train.astype('float32') / 255.\n","X_test = X_test.astype('float32') / 255.\n","\n","n_pixels = np.prod(X_train.shape[1:])\n","X_train = X_train.reshape((len(X_train), n_pixels))\n","X_test = X_test.reshape((len(X_test), n_pixels))\n","\n","print(Y_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(60000, 28, 28)\n","(10000, 28, 28)\n","[5 0 4 ... 5 6 8]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EPmAz-iOV56z"},"source":["Import + reshape and rotate MNIST data.\n","In our single-cell analogy, rotation is a treatment and the number value is a cell-type."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"odOP73MYEOBN","executionInfo":{"status":"ok","timestamp":1628802566907,"user_tz":360,"elapsed":1151,"user":{"displayName":"Natalie Davidson","photoUrl":"","userId":"15546154464477998770"}},"outputId":"66554968-c868-4b54-c718-609a8f1b3280"},"source":["(X_train_r, Y_train_r), (X_test_r, Y_test_r) = mnist.load_data()\n","\n","# now add in the rotation\n","def rotate_90(img):\n","  return cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n","\n","# rotate the training data\n","X_train_r = np.array([rotate_90(xi) for xi in X_train_r])\n","Y_train_r = Y_train\n","\n","# rotate the test data\n","X_test_r = np.array([rotate_90(xi) for xi in X_test_r])\n","Y_test_r = Y_test\n","\n","# reshape the data\n","X_train_r = X_train_r.astype('float32') / 255.\n","X_test_r = X_test_r.astype('float32') / 255.\n","\n","n_pixels = np.prod(X_train_r.shape[1:])\n","X_train_r = X_train_r.reshape((len(X_train_r), n_pixels))\n","X_test_r = X_test_r.reshape((len(X_test_r), n_pixels))\n","\n","print(X_train_r.shape)\n","print(X_test_r.shape)\n","print(Y_train_r)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(60000, 784)\n","(10000, 784)\n","[5 0 4 ... 5 6 8]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KlvGAvWvL0cy"},"source":["Demo the data, to make sure everything works"]},{"cell_type":"code","metadata":{"id":"H8dRwyJYH0em","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1628802567306,"user_tz":360,"elapsed":408,"user":{"displayName":"Natalie Davidson","photoUrl":"","userId":"15546154464477998770"}},"outputId":"f99d9068-7c3d-43af-e374-8f514e8c9d15"},"source":["# show how each method works and give some sample output\n","prop_vec = gd.gen_prop_vec_lognormal()\n","print(f\"Proportion of each MNIST number to be superimposed: {prop_vec}\")\n","\n","# print 10 random 5's\n","print(\"10 stacked 5's\")\n","single_num = gd.gen_single_num_sum(10, 5, X_train, Y_train)\n","plt.imshow(single_num.reshape(28, 28), cmap = plt.cm.gray), axis('off')\n","plt.show()\n","\n","# print 10 random 5's\n","print(\"Rotated 10 stacked 5's\")\n","single_num = gd.gen_single_num_sum(10, 5, X_train_r, Y_train_r)\n","plt.imshow(single_num.reshape(28, 28), cmap = plt.cm.gray), axis('off')\n","plt.show()\n","\n","# print 100 random 5's\n","print(\"100 stacked 5's\")\n","single_num = gd.gen_single_num_sum(100, 5, X_train, Y_train)\n","plt.imshow(single_num.reshape(28, 28), cmap = plt.cm.gray), axis('off')\n","plt.show()\n","\n","# print 50 random 0's and 50 random 1's\n","print(\"50 random 0's and 50 random 1's\")\n","zero_five_num = gd.gen_prop_num_sum([50, 50, 0, 0, 0, 0, 0, 0, 0, 0], X_train, Y_train)\n","plt.imshow(zero_five_num.reshape(28, 28), cmap = plt.cm.gray), axis('off')\n","plt.show()\n","\n","print(\"Rotated 50 random 0's and 50 random 1's\")\n","zero_five_num = gd.gen_prop_num_sum([50, 50, 0, 0, 0, 0, 0, 0, 0, 0], X_train_r, Y_train_r)\n","plt.imshow(zero_five_num.reshape(28, 28), cmap = plt.cm.gray), axis('off')\n","plt.show()\n","\n","print(\"Random Stack\")\n","y_stacked, x_stacked = gd.make_stacked_sample(X_train, Y_train)\n","plt.imshow(x_stacked.reshape(28, 28), cmap = plt.cm.gray), axis('off')\n","plt.show()\n","print(f\"Proportion of each MNIST number: {y_stacked}\")\n","\n","\n","print(\"Rotated Random Stack\")\n","y_stacked, x_stacked = gd.make_stacked_sample(X_train_r, Y_train_r)\n","plt.imshow(x_stacked.reshape(28, 28), cmap = plt.cm.gray), axis('off')\n","plt.show()\n","print(f\"Proportion of each rotated MNIST number: {y_stacked}\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Proportion of each MNIST number to be superimposed: [17 75  1  1  3  0  2  0  1  0]\n","10 stacked 5's\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Rotated 10 stacked 5's\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["100 stacked 5's\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["50 random 0's and 50 random 1's\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Rotated 50 random 0's and 50 random 1's\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Random Stack\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Proportion of each MNIST number: [ 0  0 12  0 54 14  2  1 16  1]\n","Rotated Random Stack\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Proportion of each rotated MNIST number: [ 0  0  0  0  0  0  1 97  1  1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s7Kh_UlbipH1"},"source":["Now generate all the new images"]},{"cell_type":"code","metadata":{"id":"JqGtGoojioG0"},"source":["# in a loop randomly generate images and save the X and Y\n","num_samples_train = 200000\n","num_samples_test = 20000\n","\n","# make / load training data\n","training_data_path = \"./data/stacked_train_lognorm.pkl\"\n","X_stack_train, Y_stack_train =  gd.make_all_stacked_samples(X_train, Y_train, \n","                                                         training_data_path, \n","                                                         num_samples_train)\n","\n","# make / load test data\n","testing_data_path = \"./data/stacked_test_lognorm.pkl\"\n","X_stack_test, Y_stack_test =  gd.make_all_stacked_samples(X_test, Y_test, \n","                                                         testing_data_path, \n","                                                         num_samples_test)\n","\n","\n","##################################################\n","#####. Rotated MNIST\n","##################################################\n","\n","# make / load training data\n","training_r_data_path = \"./data/stacked_rotated_train_lognorm.pkl\"\n","X_stack_train_r, Y_stack_train_r =  gd.make_all_stacked_samples(X_train_r, \n","                                                         Y_train_r, \n","                                                         training_r_data_path, \n","                                                         num_samples_train)\n","\n","\n","# make / load test data\n","testing_r_data_path = \"./data/stacked_rotated_test_lognorm.pkl\"\n","X_stack_test_r, Y_stack_test_r =  gd.make_all_stacked_samples(X_test_r, \n","                                                         Y_test_r, \n","                                                         testing_r_data_path, \n","                                                         num_samples_test)\n","\n","\n","##################################################\n","#####. Put it all together\n","##################################################\n","\n","\n","X_full_train = np.concatenate([X_stack_train, X_stack_train_r])\n","Y_full_train = np.concatenate([Y_stack_train, Y_stack_train_r])\n","\n","X_full_test = np.concatenate([X_stack_test, X_stack_test_r])\n","Y_full_test = np.concatenate([Y_stack_test, Y_stack_test_r])\n","\n","print(X_full_test.shape)\n","print(X_full_train.shape)\n","\n","### also create the condition label (regular=0, rotated=1) \n","\n","Label_train = np.concatenate([np.zeros(Y_stack_train.shape[0]), np.ones(Y_stack_train_r.shape[0])])\n","Label_test = np.concatenate([np.zeros(Y_stack_test.shape[0]), np.ones(Y_stack_test_r.shape[0])])\n","label_train = to_categorical(Label_train)\n","label_test = to_categorical(Label_test)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CqqHUIeoFFbW"},"source":["# **VAE Model Definition**\n"]},{"cell_type":"markdown","metadata":{"id":"NZNXMpBaYSpd"},"source":["## Hyperparameters"]},{"cell_type":"code","metadata":{"id":"8ALLfJ9yFIu3"},"source":["batch_size = 500\n","n_epoch = 5\n","\n","beta_kl_slack = 10\n","beta_kl_prop = 10\n","\n","# the network dimensions are 784 > 512 > proportion_dim < 512 < 784\n","n_z = 10 # latent space size, one latent dimension PER MNIST digit\n","encoder_dim = 512 # dim of encoder hidden layer\n","decoder_dim = 512 # dim of encoder hidden layer\n","decoder_out_dim = 784 # dim of decoder output layer\n","\n","activ = 'relu'\n","optim = Adam(learning_rate=0.001)\n","\n","n_x = X_full_train.shape[1]\n","n_y = Y_full_train.shape[1]\n","\n","print(f\"length of X {n_x} and length of y {n_y}\")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"83IAZUpAFOTa"},"source":["## Encoder"]},{"cell_type":"code","metadata":{"id":"gwPLYH2AFN-C"},"source":["# declare the Keras tensor we will use as input to the encoder\n","X = Input(shape=(n_x,))\n","props = Input(shape=(n_y,))\n","\n","# concatenate input with the label \n","inputs = X\n","\n","# set up encoder network\n","# this is an encoder with 512 hidden layer\n","# Dense is a functor, with given initializations (activation and hidden layer dimension)\n","# After initialization, the functor is returned and inputs is used as an arguement\n","encoder_h = Dense(encoder_dim, activation=activ, name=\"encoder_1\")(inputs)\n","\n","# now from the hidden layer, you get the mu and sigma for \n","# the latent space\n","mu_slack = Dense(n_z, activation='linear', name = \"mu_slack\")(encoder_h)\n","l_sigma_slack = Dense(n_z, activation='linear', name = \"sigma_slack\")(encoder_h)\n","\n","mu_prop = Dense(n_z, activation='linear', name = \"mu_prop\")(encoder_h)\n","l_sigma_prop = Dense(n_z, activation='linear', name = \"sigma_prop\")(encoder_h)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_9UjirfQJlrH"},"source":["## Latent Space"]},{"cell_type":"code","metadata":{"id":"ANHLiaXtJojs"},"source":["# now we need the sampler from mu and sigma\n","def sample_z(args):\n","    mu, l_sigma, n_z = args\n","    eps = K.random_normal(shape=(batch_size, n_z), mean=0., stddev=1.)\n","    return mu + K.exp(l_sigma / 2) * eps\n","\n","\n","# Sampling latent space\n","z_slack = Lambda(sample_z, output_shape = (n_z, ), name=\"z_samp_slack\")([mu_slack, l_sigma_slack, n_z])\n","z_prop = Lambda(sample_z, output_shape = (n_z, ), name=\"z_samp_prop\")([mu_prop, l_sigma_prop, n_z])\n","\n","z_concat = concat([z_slack, z_prop])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qUD9GYR0Jqtn"},"source":["## Decoder"]},{"cell_type":"code","metadata":{"id":"V9iW4RtPJsFi"},"source":["def null_f(args):\n","    return args\n","\n","# set up decoder network\n","# this is a decoder with 512 hidden layer\n","# Dense is a functor, with given initializations (activation and hidden layer dimension)\n","# After initialization, the functor is returned and inputs is used as an arguement\n","decoder_hidden = Dense(decoder_dim, activation=activ, name = \"decoder_h1\")\n","\n","# final reconstruction\n","decoder_out = Dense(decoder_out_dim, activation='sigmoid', name = \"decoder_out\")\n","\n","# this is the proportions we try to estimate\n","decoder_props = Softmax(name = \"mu_prop_pred\") \n","\n","# we use this to get sigma to do sampling later\n","decoder_sigma = Lambda(null_f, name = \"l_sigma_prop_pred\")\n","\n","# link them together\n","h_p = decoder_hidden(z_concat)\n","outputs = decoder_out(h_p)\n","\n","\n","prop_outputs = decoder_props(mu_prop)\n","sigma_outputs = decoder_sigma(l_sigma_prop)\n","\n","\n","d_in = Input(shape=(n_z+n_z,))\n","d_h1 = decoder_hidden(d_in)\n","d_out = decoder_out(d_h1)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PQN4W0fFKijp"},"source":["## Loss"]},{"cell_type":"code","metadata":{"id":"XeTxryK3Kj2f"},"source":["\n","def vae_loss(y_true, y_pred):\n","    recon = K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)\n","    kl_prop = beta_kl_prop * K.sum(K.exp(l_sigma_prop) + K.square(mu_prop) - 1. - l_sigma_prop, axis=-1)\n","    kl_rot = beta_kl_rot * K.sum(K.exp(l_sigma_rot) + K.square(mu_rot) - 1. - l_sigma_rot, axis=-1)\n","    kl_slack = beta_kl_slack * K.sum(K.exp(l_sigma_slack) + K.square(mu_slack) - 1. - l_sigma_slack, axis=-1)\n","    return recon + kl_prop + kl_rot + kl_slack\n","\n","def KL_loss(y_true, y_pred):\n","\treturn(beta_kl * K.sum(K.exp(l_sigma) + K.square(mu) - 1. - l_sigma, axis=1))\n","\n","def recon_loss(y_true, y_pred):\n","\treturn K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)\n","\n","prop_loss_scale = 100\n","def prop_loss(y_true, y_pred):\n","\treturn K.sum((y_true -  y_pred)**2, axis=-1) * prop_loss_scale\n","\n","def class_loss(y_true, y_pred):\n","    recon = K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)\n","    return recon\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d3arWPM4K4uU"},"source":["## Make the computational graph for VAE"]},{"cell_type":"code","metadata":{"id":"o7MDcy-xLS1y"},"source":["prop_vae = Model(X, [outputs, prop_outputs, sigma_outputs])\n","\n","prop_vae.compile(optimizer=optim, loss=[vae_loss, prop_loss, None])\n","\n","\n","encoder = Model(X, [z_slack, mu_prop])\n","\n","decoder = Model(d_in, d_out)\n","\n","print(prop_vae.summary())\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bSHO4halTTSL"},"source":["# **Latent Traversal**"]},{"cell_type":"markdown","metadata":{"id":"SdG6hhIEThYc"},"source":["Hyperparameters"]},{"cell_type":"markdown","metadata":{"id":"bzXuMailc2U5"},"source":["# **Experiments**"]},{"cell_type":"markdown","metadata":{"id":"tx0u5VW_c96F"},"source":["Now lets train and evaluate the model.\n","First we train with only some proportions of rotated 3's..\n","We will then decrease the proportion of rotated 3's in samples from 0.5 to 0."]},{"cell_type":"code","metadata":{"id":"oQmJNscSmNit"},"source":["# helper methods for evaluation\n","def sum_abs_error(y_pred, y_true):\n","  return sum(abs(y_pred - y_true))\n","\n","def mean_abs_error(y_pred, y_true):\n","  return np.mean(abs(y_pred - y_true))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oDZx0SwZbier"},"source":["Setup the data so that we remove all the examples with a high proportion of rotated 3's"]},{"cell_type":"code","metadata":{"id":"IDm8NwzJENFk"},"source":["# ok now we will attempt OOD\n","# remove rotated 3s\n","\n","unrot_idx = range(0, 200000)\n","rot_idx = range(200000, 400000)\n","\n","X_train_unrot = X_full_train[unrot_idx,:]\n","Y_train_unrot = Y_full_train[unrot_idx,:]\n","label_train_unrot = label_train[unrot_idx,:]\n","\n","X_train_rot = X_full_train[rot_idx,:]\n","Y_train_rot = Y_full_train[rot_idx,:]\n","label_train_rot = label_train[rot_idx,:]\n","\n","\n","# now remove all samples where 3 makes up more than 50%\n","# and is rotated\n","keep_rot_idx = Y_train_rot[:,1] < 0.1\n","X_train_rot_no3 = X_train_rot[keep_rot_idx,:]\n","Y_train_rot_no3 = Y_train_rot[keep_rot_idx,:]\n","label_train_rot_no3 = label_train_rot[keep_rot_idx,:]\n","\n","# now put it all together\n","X_train_no3rot = np.concatenate((X_train_unrot, X_train_rot_no3))\n","Y_train_no3rot = np.concatenate((Y_train_unrot, Y_train_rot_no3))\n","label_train_no3rot = np.concatenate((label_train_unrot, label_train_rot_no3))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FF4iWQDjbp9R"},"source":["Now train"]},{"cell_type":"code","metadata":{"id":"oJp0ateLdb06"},"source":["# now take a subsample of the full dataset\n","sample_size = 100000\n","rand_idx = np.random.choice(X_train_no3rot.shape[0], size=sample_size, replace=False)\n","\n","prop_vae_hist = prop_vae.fit(X_train_no3rot[rand_idx,:], \n","                                    [X_train_no3rot[rand_idx,:], \n","                                     Y_train_no3rot[rand_idx,:], \n","                                     label_train_no3rot[rand_idx,:]], \n","                      verbose = 1, batch_size=batch_size, epochs=n_epoch,\n","                      validation_data = (X_full_test, [X_full_test, Y_full_test, label_test]),\n","                      callbacks = [EarlyStopping(patience = 5)])\n","\n","\n","z_slack, mu_prop, z_rot = encoder.predict(X_full_test, batch_size=batch_size)\n","test_error = [mean_abs_error(mu_prop[idx], Y_full_test[idx]) \n","                  for idx in range(0, X_full_test.shape[1])]\n","\n","print(f\"mean test_error: {np.round(np.mean(test_error), decimals=3)}\\n\"\n","      f\"median test_error: {np.round(np.median(test_error), decimals=3)}\\n\"\n","      f\"max test_error: {np.round(np.max(test_error), decimals=3)}\")\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6dtLBD6Z5O0b"},"source":["print(z_rot)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"deFsNjxP0Kdn"},"source":["# **Inspect the output**"]},{"cell_type":"markdown","metadata":{"id":"Nl1HLVLX0mm6"},"source":["We will take two examples from our training and see how well it reconstructs.\n","We first look at the ground truth so we know what we should expect."]},{"cell_type":"code","metadata":{"id":"Y7UwaFGOX-TN"},"source":["plot_idx = 0 #20\n","plt.imshow(X_full_train[plot_idx].reshape(28, 28), cmap = plt.cm.gray)\n","plt.show()\n","print(Y_full_train[plot_idx])\n","print(label_train[plot_idx])\n","\n","plt.imshow(X_full_train[200000+plot_idx].reshape(28, 28), cmap = plt.cm.gray)\n","plt.show()\n","print(Y_full_train[200000+plot_idx])\n","print(label_train[200000+plot_idx])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vk8Czv7a0xlw"},"source":["Now that we know what is expected, let's see what we get from the model. We find that out of our encoder, after applying ReLU, we get pretty close to the expected proportions."]},{"cell_type":"code","metadata":{"id":"fRlIK-o2YMt2"},"source":["plot_idx = 0\n","\n","z_slack, mu_prop, z_rot = encoder.predict(X_full_train, batch_size=batch_size)\n","encoded_X0 = mu_prop[plot_idx]\n","rotated_vec = z_rot[plot_idx]\n","print(f\"1-hot encoded condition vector: {Y_full_train[plot_idx]}\\n\")\n","\n","print(f\"output from encoder: {encoded_X0}\")\n","\n","encoded_X0[encoded_X0<0] = 0\n","print(f\"output from encoder (ReLU applied): {encoded_X0}\")\n","\n","print(f\"rotation: {label_train[plot_idx]}\")\n","print(f\"rotation (noReLU applied): {rotated_vec}\")\n","rotated_vec[rotated_vec<0] = 0\n","print(f\"rotation (ReLU applied): {rotated_vec}\")\n","\n","\n","encoded_X0 = mu_prop[200000+plot_idx]\n","rotated_vec = z_rot[200000+plot_idx]\n","\n","print(f\"1-hot encoded condition vector: {Y_full_train[200000+plot_idx]}\")\n","print(f\"output from encoder (no ReLU applied): {encoded_X0}\")\n","encoded_X0[encoded_X0<0] = 0\n","print(f\"output from encoder (ReLU applied): {encoded_X0}\")\n","\n","print(f\"rotation: {label_train[200000+plot_idx]}\")\n","print(f\"output from encoder (noReLU applied): {rotated_vec}\")\n","rotated_vec[rotated_vec<0] = 0\n","print(f\"output from encoder (ReLU applied): {rotated_vec}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PGggGQZ6YT-T"},"source":["# plot proportions\n","z_slack, mu_prop, z_rot = encoder.predict(X_full_test, batch_size=batch_size)\n","z_test = mu_prop\n","encodings= np.asarray(z_test)\n","encodings = encodings.reshape(X_full_test.shape[0], n_z)\n","tsne_idx = np.random.choice(encodings.shape[0], size=5000, replace=False)\n","\n","\n","time_start = time.time()\n","tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n","tsne_results = tsne.fit_transform(encodings[tsne_idx,:])\n","print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n","\n","\n","plot_df = pd.DataFrame(tsne_results[:,0:2])\n","print(tsne_results.shape)\n","print(plot_df.shape)\n","plot_df.columns = ['tsne_0', 'tsne_1']\n","plot_df['label'] = Label_test[tsne_idx]\n","\n","sns.scatterplot(\n","    x=\"tsne_0\", y=\"tsne_1\",\n","    data=plot_df,\n","    hue=\"label\",\n","    palette=sns.color_palette(\"hls\", 2),\n","    legend=\"full\",\n","    alpha=0.3\n",")\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"keGxBjcy-OxW"},"source":["# plot rotation\n","z_test = z_rot\n","encodings= np.asarray(z_test)\n","encodings = encodings.reshape(X_full_test.shape[0], n_label)\n","tsne_idx = np.random.choice(encodings.shape[0], size=5000, replace=False)\n","\n","\n","time_start = time.time()\n","tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n","tsne_results = tsne.fit_transform(encodings[tsne_idx,:])\n","print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n","\n","\n","plot_df = pd.DataFrame(tsne_results[:,0:2])\n","print(tsne_results.shape)\n","print(plot_df.shape)\n","plot_df.columns = ['tsne_0', 'tsne_1']\n","plot_df['label'] = Label_test[tsne_idx]\n","\n","sns.scatterplot(\n","    x=\"tsne_0\", y=\"tsne_1\",\n","    data=plot_df,\n","    hue=\"label\",\n","    palette=sns.color_palette(\"hls\", 2),\n","    legend=\"full\",\n","    alpha=0.3\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xGC5KAHt-VRs"},"source":["# plot remaining variance\n","z_test = z_slack\n","encodings= np.asarray(z_test)\n","encodings = encodings.reshape(X_full_test.shape[0], n_z)\n","tsne_idx = np.random.choice(encodings.shape[0], size=5000, replace=False)\n","\n","\n","time_start = time.time()\n","tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n","tsne_results = tsne.fit_transform(encodings[tsne_idx,:])\n","print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n","\n","\n","plot_df = pd.DataFrame(tsne_results[:,0:2])\n","print(tsne_results.shape)\n","print(plot_df.shape)\n","plot_df.columns = ['tsne_0', 'tsne_1']\n","plot_df['label'] = Label_test[tsne_idx]\n","\n","sns.scatterplot(\n","    x=\"tsne_0\", y=\"tsne_1\",\n","    data=plot_df,\n","    hue=\"label\",\n","    palette=sns.color_palette(\"hls\", 2),\n","    legend=\"full\",\n","    alpha=0.3\n",")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4fVjMpfvb8Mw"},"source":["print(X_full_test[0].shape) \n","print(Y_full_test[0].shape)\n","\n","def sum_abs_error(y_pred, y_true):\n","  return sum(abs(y_pred - y_true))\n","\n","def mean_abs_error(y_pred, y_true):\n","  return np.mean(abs(y_pred - y_true))\n","\n","output_prop_test = prop_vae.predict(X_full_test, batch_size=batch_size)[1]\n","\n","test_error = [mean_abs_error(output_prop_test[idx], Y_full_test[idx]) \n","                  for idx in range(0, X_full_test.shape[0])]\n","\n","print(f\"mean test_error: {np.round(np.mean(test_error), decimals=3)}\\n\"\n","      f\"median test_error: {np.round(np.median(test_error), decimals=3)}\\n\"\n","      f\"max test_error: {np.round(np.max(test_error), decimals=3)}\")\n","\n","\n","output_prop = prop_vae.predict(X_full_train, batch_size=batch_size)[1]\n","train_error = [mean_abs_error(output_prop[idx], Y_full_train[idx]) \n","                  for idx in range(0, X_full_train.shape[0])]\n","\n","print(f\"mean train_error: {np.round(np.mean(train_error), decimals=3)}\\n\"\n","      f\"median train_error: {np.round(np.median(train_error), decimals=3)}\\n\"\n","      f\"max train_error: {np.round(np.max(train_error), decimals=3)}\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HViu-WrnIDva"},"source":["\n","def method_sample_z(args):\n","    mu, l_sigma = args\n","    eps = np.random.normal(size=(batch_size, n_z), loc=0., scale=1.)\n","    return mu + np.exp(l_sigma / 2) * eps\n","\n","def sample_digit(digit, Y_test, digit_scale, rotate):\n","  digit_idx = np.where(Y_test == digit)\n","\n","  label_vec = np.array([1., 0.]).reshape((1, 2))\n","  if rotate:\n","    label_vec = np.array([0., 1.]).reshape((1, 2))\n","\n","  pred_input = X_full_test[digit_idx[0]]\n","  rand_idx = np.random.choice(pred_input.shape[0], size=batch_size, replace=False)\n","  pred_input = pred_input[rand_idx]\n","\n","  test_X, test_mu, test_label, test_lsigma = prop_vae.predict(pred_input, batch_size=batch_size)\n","\n","  encoded_X0 = np.ones(10)*0.0001\n","  encoded_X0[digit] = digit_scale\n","  rand_lsigma = np.random.random_integers(low = 0, high = 249)\n","  z_0_digit = method_sample_z([encoded_X0, test_lsigma])\n","  z_0_digit = z_0_digit[rand_lsigma].reshape((1,10))\n","  return(z_0_digit)\n","\n","digit_img = 1\n","\n","keep_rot_idx = Y_full_test[:,digit_img] > 0.9\n","print(sum(keep_rot_idx))\n","X_example = X_full_test[keep_rot_idx,]\n","z_slack, mu_prop, z_rot = encoder.predict(X_example[0:batch_size,:], batch_size=batch_size)\n","\n","z_0_digit = sample_digit(digit_img, Y_test, 10, rotate=True)\n","plt.figure(figsize=(3, 3))\n","\n","# it is rotated\n","rotate_1hot = np.array([0., 10.])\n","\n","# slack, prop, rot\n","slack_sample = z_slack[0]\n","slack_sample = [0,0,0,0,0,0,0,0,0,0]\n","pred_input = np.concatenate([slack_sample, z_0_digit[0], rotate_1hot]).reshape((1,22))\n","\n","print(f\"rotated {digit_img}\")\n","plt.imshow(decoder.predict(pred_input).reshape(28,28), cmap = plt.cm.gray), axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jRwSY99kY51D"},"source":["img_it = 0\n","sides = 10\n","slack_sample = [0,0,0,0,0,0,0,0,0,0]\n","rotate_scale = 10\n","\n","\n","rotate_1hot = np.array([rotate_scale, 0.])\n","rotate_val = False\n","for i in range(0, sides):\n","    for j in range(0, sides):\n","        z_0_digit = sample_digit(i, Y_test, 2**j, rotate=rotate_val)\n","\n","        digit_img = i\n","\n","        keep_rot_idx = Y_full_test[:,digit_img] > 0.9\n","        X_example = X_full_test[keep_rot_idx,]\n","        z_slack, mu_prop, z_rot = encoder.predict(X_example[0:batch_size,:], batch_size=batch_size)\n","\n","        # slack, prop, rot\n","        slack_sample = z_slack[0]\n","        pred_input = np.concatenate([slack_sample, z_0_digit[0], rotate_1hot]).reshape((1,22))\n","\n","        decoded = decoder.predict(pred_input)\n","        subplot(sides, sides, 1 + img_it)\n","        img_it +=1\n","        plt.imshow(decoded.reshape(28, 28), cmap = plt.cm.gray), axis('off')\n","\n","plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=.2)\n","plt.show()\n","\n","\n","rotate_1hot = np.array([0., rotate_scale])\n","rotate_val = True\n","img_it = 0\n","sides = 10\n","for i in range(0, sides):\n","    for j in range(0, sides):\n","        z_0_digit = sample_digit(i, Y_test, 2**j, rotate=rotate_val)\n","        digit_img = i\n","\n","        keep_rot_idx = Y_full_test[:,digit_img] > 0.9\n","        X_example = X_full_test[keep_rot_idx,]\n","        z_slack, mu_prop, z_rot = encoder.predict(X_example[0:batch_size,:], batch_size=batch_size)\n","\n","        # slack, prop, rot\n","        slack_sample = z_slack[0]\n","        pred_input = np.concatenate([slack_sample, z_0_digit[0], rotate_1hot]).reshape((1,22))\n","\n","        decoded = decoder.predict(pred_input)\n","        subplot(sides, sides, 1 + img_it)\n","        img_it +=1\n","        plt.imshow(decoded.reshape(28, 28), cmap = plt.cm.gray), axis('off')\n","\n","plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=.2)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x2S_AdzcHncV"},"source":["# predict rotated numbers\n","\n","# normalizing the data to make the neural network easier to learn\n","x_train_r = normalize(X_train_r, axis=1)\n","x_test_r = normalize(X_test_r, axis=1)\n","\n","#choosing the sequential model\n","classification_model = Sequential()\n","\n","#defining the architecture of the model\n","X_class = Input(shape=(n_x,))\n","classification_model.add(X_class)\n","classification_model.add(Dense(512, activation='relu'))\n","classification_model.add(Dense(128, activation='relu'))\n","classification_model.add(Dense(10, activation='softmax'))\n","\n","#defining the parameters to train the model\n","classification_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n","\n","#training the model\n","classification_model.fit(x_train_r,Y_train_r,epochs=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QWx2eSjsIUeR"},"source":["\n","num_correct = 0\n","num_digits = 10\n","num_rep = 100\n","rotate_1hot = np.array([0., 10])\n","rotate_val = True\n","slack_sample = method_sample_z([0,1])[0]\n","acc = []\n","for digit_idx in range(0, num_digits):\n","  num_correct = 0\n","  for idx_rep in range(0, num_rep):\n","    z_0_digit = sample_digit(digit_idx, Y_test, 2**4, rotate=rotate_val)\n","    digit_img = digit_idx\n","\n","    keep_rot_idx = Y_full_test[:,digit_img] > 0.9\n","    X_example = X_full_test[keep_rot_idx,]\n","    z_slack, mu_prop, z_rot = encoder.predict(X_example[0:batch_size,:], batch_size=batch_size)\n","\n","    # slack, prop, rot\n","    slack_sample = z_slack[10]\n","    slack_sample = [0,0,0,0,0,0,0,0,0,0]\n","    pred_input = np.concatenate([slack_sample, z_0_digit[0], rotate_1hot]).reshape((1,22))\n","\n","\n","    decoded = decoder.predict(pred_input)\n","    predictions = classification_model.predict(decoded)\n","    #print(f\"true: {idx} pred: {np.argmax(predictions)}\")\n","    if(digit_idx == np.argmax(predictions)):\n","      num_correct += 1\n","  acc = np.append(acc, num_correct)\n","\n","print(np.mean(acc))\n","print(acc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jiRyMXm43PAS"},"source":["digit_idx=1\n","for idx_rep in range(0, 10):\n","  z_0_digit = sample_digit(digit_idx, Y_test, 2**4, rotate=rotate_val)\n","  digit_img = digit_idx\n","\n","  keep_rot_idx = Y_full_test[:,digit_img] > 0.9\n","  X_example = X_full_test[keep_rot_idx,]\n","  z_slack, mu_prop, z_rot = encoder.predict(X_example[0:batch_size,:], batch_size=batch_size)\n","\n","  # slack, prop, rot\n","  slack_sample = [0,0,0,0,0,0,0,0,0,0]\n","  pred_input = np.concatenate([slack_sample, z_0_digit[0], rotate_1hot]).reshape((1,22))\n","\n","\n","  decoded = decoder.predict(pred_input)\n","  predictions = classification_model.predict(decoded)\n","  print(f\" pred: {predictions}\")\n","\n","  print(f\"rotated {digit_img}\")\n","  plt.imshow(decoder.predict(pred_input).reshape(28,28), cmap = plt.cm.gray), axis('off')\n","  plt.show()\n","\n"],"execution_count":null,"outputs":[]}]}